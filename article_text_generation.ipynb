{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ESGIND\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import StringLookup,Embedding,GRU,Input,Dense\n",
    "from keras import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JF-RKjsvqa-7"
   },
   "outputs": [],
   "source": [
    "with open('articles_text.txt','r',encoding='utf-8') as fi:\n",
    "    text=fi.read().strip().lower().replace('ï','').replace('…','').replace('\\u202f','').replace('\\xa0','').replace('•','').replace('ü','').\\\n",
    "    replace('|','').replace('″','').replace('‘','').replace('_','').replace('—','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rise of e-health and its impact on humans by the year 2030the rise of e-health, or the use of electr'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punc=string.punctuation\n",
    "vocab=list(set(text))\n",
    "for i in vocab:\n",
    "    if i in punc:\n",
    "        vocab.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(716931,), dtype=string, numpy=array([b'r', b'i', b's', ..., b'f', b's', b'.'], dtype=object)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_tensor=tf.strings.unicode_split(text,'UTF-8')\n",
    "chars_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_ids=StringLookup(vocabulary=vocab)\n",
    "ids_to_chars=StringLookup(vocabulary=chars_to_ids.get_vocabulary(),invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "charsids_tensor=chars_to_ids(chars_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(716931,), dtype=int64, numpy=array([ 8, 17,  1, ..., 33,  1, 44], dtype=int64)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsids_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(716931,), dtype=string, numpy=array([b'r', b'i', b's', ..., b'f', b's', b'.'], dtype=object)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_chars(charsids_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(chars_to_ids.get_vocabulary())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_char=lambda ids:tf.strings.reduce_join(ids_to_chars(ids),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'rise '>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_char(charsids_tensor[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'rise of e[UNK]health and its impact on humans by the year 2030the rise of e[UNK]health, or the use of electro'\n",
      "b'nic means to facilitate health care, has been a major development in the healthcare industry in recen'\n",
      "b't years[UNK] the use of technology to improve access to healthcare and make it more efficient has the pot'\n",
      "b'ential to revolutionize the way we think about healthcare and its delivery[UNK] by 2030, it is likely tha'\n",
      "b't e[UNK]health will have a significant impact on the way we receive and provide healthcare, and this essa'\n"
     ]
    }
   ],
   "source": [
    "seq_len=100\n",
    "dataset=tf.data.Dataset.from_tensor_slices(charsids_tensor)\n",
    "seq_dataset=dataset.batch(seq_len+1,drop_remainder=True)\n",
    "for seq in seq_dataset.take(5):\n",
    "    print(join_char(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'rise of e[UNK]health and its impact on humans by the year 2030the rise of e[UNK]health, or the use of electr'\n",
      "b'ise of e[UNK]health and its impact on humans by the year 2030the rise of e[UNK]health, or the use of electro'\n"
     ]
    }
   ],
   "source": [
    "seq_data=seq_dataset.map(lambda x:(x[:-1],x[1:]))\n",
    "for inp,out in seq_data.take(1):\n",
    "    print(join_char(inp).numpy())\n",
    "    print(join_char(out).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "buffer_size=15000\n",
    "data=seq_data.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,o in data.take(1):\n",
    "    inp,out=i,o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_generation_model(vocab_size, embedding_dim, rnn_units,states=None):\n",
    "    input_sequence = Input(shape=(None,), name='input_sequence')\n",
    "    embedding_layer = Embedding(vocab_size, embedding_dim, name='embedding')(input_sequence)\n",
    "    \n",
    "    gru_layer = GRU(rnn_units, return_sequences=True, return_state=True, name='gru')\n",
    "    if states is None:\n",
    "        states = gru_layer.get_initial_state(embedding_layer)\n",
    "    gru_seq, gru_states = gru_layer(embedding_layer, initial_state=states)\n",
    "\n",
    "    output_logits = Dense(vocab_size, name='output')(gru_seq)\n",
    "    model = Model(inputs=input_sequence, outputs=output_logits, name='text_generation_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_dim=256\n",
    "rnn_units=512\n",
    "model1=build_text_generation_model(vocab_size,emd_dim,rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 46), dtype=float32, numpy=\n",
       "array([[-0.00771305,  0.00603304,  0.01988032, ...,  0.00415304,\n",
       "         0.01138706,  0.00236001],\n",
       "       [-0.00885162,  0.00186647,  0.01069327, ...,  0.00630166,\n",
       "        -0.01088867,  0.00648821],\n",
       "       [ 0.00329366,  0.00880979, -0.01110901, ..., -0.00476713,\n",
       "         0.00717848, -0.00473939],\n",
       "       ...,\n",
       "       [-0.00504883,  0.00395807,  0.01773222, ...,  0.0049665 ,\n",
       "         0.02405166, -0.00577515],\n",
       "       [-0.00855392,  0.00175534,  0.01059595, ...,  0.00522615,\n",
       "        -0.00388215,  0.00141557],\n",
       "       [ 0.00259581,  0.00940419, -0.01040717, ..., -0.00604095,\n",
       "         0.01112475, -0.00789805]], dtype=float32)>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(i)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile('adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "111/111 [==============================] - 98s 852ms/step - loss: 2.8146\n",
      "Epoch 2/30\n",
      "111/111 [==============================] - 96s 859ms/step - loss: 2.2516\n",
      "Epoch 3/30\n",
      "111/111 [==============================] - 95s 851ms/step - loss: 1.9927\n",
      "Epoch 4/30\n",
      "111/111 [==============================] - 104s 933ms/step - loss: 1.7649\n",
      "Epoch 5/30\n",
      "111/111 [==============================] - 101s 905ms/step - loss: 1.5882\n",
      "Epoch 6/30\n",
      "111/111 [==============================] - 98s 871ms/step - loss: 1.4700\n",
      "Epoch 7/30\n",
      "111/111 [==============================] - 99s 884ms/step - loss: 1.3900\n",
      "Epoch 8/30\n",
      "111/111 [==============================] - 95s 845ms/step - loss: 1.3318\n",
      "Epoch 9/30\n",
      "111/111 [==============================] - 101s 900ms/step - loss: 1.2864\n",
      "Epoch 10/30\n",
      "111/111 [==============================] - 95s 842ms/step - loss: 1.2499\n",
      "Epoch 11/30\n",
      "111/111 [==============================] - 99s 882ms/step - loss: 1.2182\n",
      "Epoch 12/30\n",
      "111/111 [==============================] - 102s 909ms/step - loss: 1.1904\n",
      "Epoch 13/30\n",
      "111/111 [==============================] - 102s 915ms/step - loss: 1.1648\n",
      "Epoch 14/30\n",
      "111/111 [==============================] - 98s 871ms/step - loss: 1.1413\n",
      "Epoch 15/30\n",
      "111/111 [==============================] - 94s 843ms/step - loss: 1.1189\n",
      "Epoch 16/30\n",
      "111/111 [==============================] - 97s 870ms/step - loss: 1.0974\n",
      "Epoch 17/30\n",
      "111/111 [==============================] - 100s 891ms/step - loss: 1.0768\n",
      "Epoch 18/30\n",
      "111/111 [==============================] - 113s 1s/step - loss: 1.0559\n",
      "Epoch 19/30\n",
      "111/111 [==============================] - 122s 1s/step - loss: 1.0354\n",
      "Epoch 20/30\n",
      "111/111 [==============================] - 111s 993ms/step - loss: 1.0149\n",
      "Epoch 21/30\n",
      "111/111 [==============================] - 109s 974ms/step - loss: 0.9941\n",
      "Epoch 22/30\n",
      "111/111 [==============================] - 101s 905ms/step - loss: 0.9733\n",
      "Epoch 23/30\n",
      "111/111 [==============================] - 103s 916ms/step - loss: 0.9528\n",
      "Epoch 24/30\n",
      "111/111 [==============================] - 105s 937ms/step - loss: 0.9310\n",
      "Epoch 25/30\n",
      "111/111 [==============================] - 106s 944ms/step - loss: 0.9106\n",
      "Epoch 26/30\n",
      "111/111 [==============================] - 103s 916ms/step - loss: 0.8889\n",
      "Epoch 27/30\n",
      "111/111 [==============================] - 96s 860ms/step - loss: 0.8670\n",
      "Epoch 28/30\n",
      "111/111 [==============================] - 103s 925ms/step - loss: 0.8456\n",
      "Epoch 29/30\n",
      "111/111 [==============================] - 102s 913ms/step - loss: 0.8241\n",
      "Epoch 30/30\n",
      "111/111 [==============================] - 102s 909ms/step - loss: 0.8030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26863aa71f0>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=30\n",
    "callback=ModelCheckpoint('text_model.h5',monitor='loss',mode='min',save_best_only=True)\n",
    "model.fit(data,epochs=epochs,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('text_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input(shape=(None,), name='input_sequence')\n",
    "initial_states=Input(shape=(512,),name='initial_states')\n",
    "embedding_layer = Embedding(vocab_size, 256, name='embedding')(input_sequence)\n",
    "\n",
    "gru_layer = GRU(rnn_units, return_sequences=True, return_state=True, name='gru')\n",
    "gru_seq, gru_states = gru_layer(embedding_layer, initial_states)\n",
    "\n",
    "output_logits = Dense(vocab_size, name='output')(gru_seq)\n",
    "model = Model(inputs=[input_sequence,initial_states], outputs=[output_logits,gru_states], name='text_generation_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits,final_state=model([w_id_batch,state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([30], dtype=int64)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.categorical(logits[:,-1,:],num_samples=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chars(model,text,chars_to_id,ids_to_chars,states=None):\n",
    "    uni=tf.strings.unicode_split(text,'UTF-8')\n",
    "    w_id=chars_to_ids(w_split)\n",
    "    w_id_batch=tf.reshape(w_id,(1,-1))\n",
    "    if states is None:\n",
    "        states=tf.zeros([1,512])\n",
    "    logits,state=model([w_id_batch,states])\n",
    "    id_char=tf.random.categorical(logits[:,-1,:],num_samples=1)[0]\n",
    "    next_char=ids_to_chars(id_char)\n",
    "    return next_char,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=None\n",
    "text='some happy'\n",
    "result=[]\n",
    "for i in range(1000):\n",
    "    text,state=predict_chars(model,text,chars_to_ids,ids_to_chars,state)\n",
    "    result.append(text.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'bbxb[UNK]x[UNK]bbb x[UNK]8b8jb7xbbx[UNK]jjb[UNK]bb7xkx[UNK]b[UNK]b[UNK]xb[UNK]\\xe2\\x82\\xb9xbzx\\xe2\\x82\\xb9xb8bbb[UNK]7b[UNK][UNK]x[UNK]87[UNK]b7[UNK][UNK]bb[UNK]bbb[UNK]x[UNK]bbb[UNK]\\xe2\\x82\\xb9[UNK]7b[UNK]b[UNK][UNK][UNK][UNK]b[UNK]bb8[UNK][UNK] xxnbn[UNK]bx[UNK] bjbv[UNK]b[UNK]b7xd[UNK][UNK]7[UNK]b v[UNK]xjb[UNK][UNK]4[UNK][UNK]b7[UNK]7b7t[UNK]b8b[UNK]\\n8bj[UNK]j2[UNK][UNK]n[UNK]7[UNK]/%x8bvxx[UNK]wj[UNK]7x[UNK]bxb7b7j9x[UNK]7[UNK]bbb\\n[UNK]b[UNK]7bbbb[UNK][UNK][UNK]bb97[UNK]xxj[UNK]b7bxbbbx4b[UNK]77b8b7b7[UNK]7b[UNK]b7[UNK]b[UNK]xzx9bbe7[UNK][UNK]bk7bx9xb77xxbbvbbbbxxbb[UNK][UNK]bxb[UNK][UNK] xtb[UNK]bb[UNK]xbb77sb7/[UNK]et[UNK]x4b7[UNK]b[UNK][UNK]a77b[UNK]b87x[UNK]/7[UNK][UNK]b7b[UNK]bbb7sb[UNK]b[UNK]bebbxxx[UNK]b [UNK]7b[UNK]bb[UNK]x[UNK]b[UNK][UNK][UNK][UNK]7[UNK][UNK] 7[UNK]/sbn[UNK]x bbb4bb[UNK]b[UNK]b7b[UNK]bx7[UNK]x[UNK]bbx[UNK][UNK][UNK][UNK]bb[UNK]b[UNK]b[UNK]bbbxb7bb[UNK][UNK]b[UNK][UNK]7\\nb7xjjb8[UNK]jb[UNK][UNK]b8[UNK][UNK]7[UNK]4[UNK][UNK]z[UNK][UNK]b[UNK]bb7 bnb7[UNK]7bxb[UNK]bx\\xe2\\x82\\xb9[UNK]xb[UNK]7xx[UNK] 7x7xox77bvz%[UNK]7zbbx[UNK]bbbxxb[UNK]7[UNK]v[UNK]bebbjxx7sbbbx[UNK]b7b7[UNK]bb[UNK]7x [UNK]7[UNK][UNK][UNK]bx[UNK]\\n[UNK]8[UNK]bb[UNK][UNK][UNK]d[UNK]b7bb[UNK]7nb[UNK]s[UNK]x[UNK][UNK][UNK]b x7bbvb7x 7[UNK]b8b[UNK]7[UNK]b[UNK]b7\\xe2\\x82\\xb9 bb8[UNK]1xj7\\xe2\\x82\\xb9[UNK]b[UNK]xbbxbj7/b7bb[UNK]bbb[UNK]bb[UNK]bbbjb[UNK]bb[UNK]\\njbbb[UNK][UNK]bxsb[UNK]/b[UNK][UNK]8v[UNK][UNK]7[UNK][UNK]7x4[UNK][UNK][UNK]xb[UNK]x7[UNK]b[UNK]x7b[UNK][UNK]b[UNK]jx/b7z[UNK][UNK]jb0[UNK]b7bb[UNK][UNK]b[UNK][UNK][UNK][UNK][UNK]bx[UNK]bb[UNK]7[UNK]xb[UNK][UNK]b[UNK][UNK]b7bbb[UNK](b[UNK][UNK]7jxb bbj[UNK]b7[UNK][UNK]j[UNK][UNK]b8[UNK][UNK]bb4[UNK]bxxb[UNK][UNK]b[UNK]x[UNK]bx[UNK]bx7[UNK]b[UNK][UNK][UNK][UNK]x[UNK]bex[UNK]b7[UNK]xxbb7b[UNK]x[UNK]7[UNK][UNK]b8xv [UNK][UNK]b[UNK]bb[UNK]7b[UNK]b[UNK][UNK]b[UNK][UNK]7[UNK]bxbxv[UNK] bb[UNK]7xb8bx7[UNK][UNK]x[UNK][UNK][UNK]bb[UNK]b[UNK]b[UNK][UNK]b[UNK][UNK]v7x7b7b[UNK]77j\\nbbbbb[UNK][UNK][UNK][UNK]b8777b[UNK][UNK]/xb77e[UNK][UNK]bbsb4xb[UNK]xx[UNK]bbjx7bvs[UNK]x[UNK]n8bb[UNK][UNK][UNK]bbbb[UNK][UNK]b[UNK]xxb[UNK]8[UNK]xx7[UNK] be[UNK]8sv[UNK]7xb77[UNK]bbjbjxb[UNK]b[UNK]xwb%b/[UNK]b[UNK][UNK]8[UNK]\\n9b bb7b7bbbbbbb[UNK]n[UNK]7[UNK][UNK]b[UNK]j77bbb[UNK]xs7b'>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
